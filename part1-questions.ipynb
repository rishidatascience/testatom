{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408df7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aima3\n",
      "  Downloading aima3-1.0.11-py2.py3-none-any.whl (150 kB)\n",
      "\u001b[K     |████████████████████████████████| 150 kB 4.5 MB/s eta 0:00:01    |██████▌                         | 30 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jupyter in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from aima3) (1.0.0)\n",
      "Requirement already satisfied: tqdm in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from aima3) (4.59.0)\n",
      "Collecting networkx==1.11\n",
      "  Downloading networkx-1.11-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 14.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from networkx==1.11->aima3) (5.0.6)\n",
      "Requirement already satisfied: nbconvert in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jupyter->aima3) (6.0.7)\n",
      "Requirement already satisfied: qtconsole in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jupyter->aima3) (5.0.3)\n",
      "Requirement already satisfied: jupyter-console in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jupyter->aima3) (6.4.0)\n",
      "Requirement already satisfied: ipykernel in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jupyter->aima3) (5.3.4)\n",
      "Requirement already satisfied: ipywidgets in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jupyter->aima3) (7.6.3)\n",
      "Requirement already satisfied: notebook in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jupyter->aima3) (6.3.0)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->aima3) (7.22.0)\n",
      "Requirement already satisfied: appnope in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->aima3) (0.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->aima3) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->aima3) (6.1.12)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->aima3) (5.0.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->aima3) (4.8.0)\n",
      "Requirement already satisfied: backcall in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->aima3) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->aima3) (3.0.17)\n",
      "Requirement already satisfied: pygments in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->aima3) (2.8.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->aima3) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pickleshare in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->aima3) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->aima3) (0.17.2)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->aima3) (0.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->jupyter->aima3) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->aima3) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from traitlets>=4.1.0->ipykernel->jupyter->aima3) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipywidgets->jupyter->aima3) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipywidgets->jupyter->aima3) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from ipywidgets->jupyter->aima3) (1.0.0)\n",
      "Requirement already satisfied: jupyter-core in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->aima3) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->aima3) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->aima3) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->aima3) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->aima3) (1.15.0)\n",
      "Requirement already satisfied: argon2-cffi in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->aima3) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->aima3) (0.10.1)\n",
      "Requirement already satisfied: jinja2 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->aima3) (2.11.3)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->aima3) (1.5.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->aima3) (20.0.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->aima3) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jupyter-client->ipykernel->jupyter->aima3) (2.8.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->aima3) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter->aima3) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from jinja2->notebook->jupyter->aima3) (1.1.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->aima3) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->aima3) (0.8.4)\n",
      "Requirement already satisfied: testpath in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->aima3) (0.4.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->aima3) (0.3)\n",
      "Requirement already satisfied: defusedxml in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->aima3) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->aima3) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->aima3) (0.5.3)\n",
      "Requirement already satisfied: bleach in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->aima3) (3.3.0)\n",
      "Requirement already satisfied: nest-asyncio in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->aima3) (1.5.1)\n",
      "Requirement already satisfied: async-generator in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->aima3) (1.10)\n",
      "Requirement already satisfied: webencodings in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->aima3) (0.5.1)\n",
      "Requirement already satisfied: packaging in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->aima3) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from packaging->bleach->nbconvert->jupyter->aima3) (2.4.7)\n",
      "Requirement already satisfied: qtpy in /Users/dollymac/opt/anaconda3/lib/python3.8/site-packages (from qtconsole->jupyter->aima3) (1.9.0)\n",
      "Installing collected packages: networkx, aima3\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.5\n",
      "    Uninstalling networkx-2.5:\n",
      "      Successfully uninstalled networkx-2.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikit-image 0.18.1 requires networkx>=2.0, but you have networkx 1.11 which is incompatible.\u001b[0m\n",
      "Successfully installed aima3-1.0.11 networkx-1.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install aima3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66ea8cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from aima3 import learning\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096d0c3",
   "metadata": {},
   "source": [
    "### 1. Activation Functions\n",
    "Before we see how neural networks work, we first concentrate on activation functions. We will give some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4124bf1",
   "metadata": {},
   "source": [
    "#### Sigmoid Function\n",
    "The sigmoid function takes the \"S\" shape. There are several functions that give a sigmoid function, but typically in neural networks, when we refer to *the* sigmoid function we mean the logistic function, which is:\n",
    "$$s(z) := \\dfrac{1}{1 + e^{-z}}.$$\n",
    "Let us plot this function for several values of $z$ and see why we have the S-shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72e34ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the sigmoid function\n",
    "def sigmoid(z):\n",
    "    \"\"\"The sigmoid function.\"\"\"\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "#generic plot function\n",
    "def plot_function(f, x):\n",
    "    plt.plot(x, f(x))\n",
    "    try:\n",
    "        title = f.__name__\n",
    "        plt.title('%s' % title)\n",
    "        plt.savefig('%s.png' % title)\n",
    "    except AttributeError as e:\n",
    "        print(e)\n",
    "    plt.savefig('out.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5446a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAijElEQVR4nO3deXiU5d328e+P7CEhARK2hLAIsogoEHG3WvcVtbZ1qbZoa31e7Ws361a1VfuotU+Xp1pxqVVblbpVqVrRtmptrcgiOwTDHrYkBLKS/ff+kcibxiADTHLPcn6OI0cymYuZcyA5j4tr7vu+zN0REZHo1yvoACIiEh4qdBGRGKFCFxGJESp0EZEYoUIXEYkRKnQRkRihQpeYY2a3mNljkfa8ZrbOzE7pyUwSX0zHoYv0DDNbB3zd3f8adBaJTZqhi4jECBW6RDUzu9HMNplZtZkVmdnJZvYjM/tDhzFXmNl6M9tuZrd1XPpoH/u8mf2h/TGWmNnBZnazmZWa2UYzO63DYw0xs1lmVmFmxWb2jQ73dX7eyzs876099Xci8UuFLlHLzMYA1wFHuHsmcDqwrtOY8cBvgMuAwUAWkNfpoc4Ffg/0BT4CZtP2u5EH3Ak83GHss0AJMAS4CPhvMzu5i2zjgYeAy9vH9gfy9/vFioRAhS7RrAVIAcabWZK7r3P31Z3GXAT82d3/6e6NwO1A5zeO3nP32e7eDDwP5AL3unsTMBMYbmbZZjYUOA640d3r3X0h8Bhtpd3ZRcCr7v4Pd28AbgNaw/KqRfZAhS5Ry92LgW8DPwJKzWymmQ3pNGwIsLHDn6kDtncas63D17uAcndv6XAbIKP9sSrcvbrD+PV8esbf1fPWdvG8ImGlQpeo5u7PuPtxwDDaZt73dRqyhQ5LHWaWRtvyx/7YDPQzs8wO3ysANnUxdgswtMPzph/A84qERIUuUcvMxpjZ580sBainbTbd0mnYC8C5ZnaMmSUDPwZsf57P3TcC7wP3mFmqmU0ErgKe7mL4C8A5ZnZc+/PeiX7fpJvpB0yiWQpwL1AObAUGALd0HODuy4Bv0bYWvgWoBkqBhv18zkuA4bTN1v8E3OHub3Ue1P681wLPtD/vDtreTBXpNjqxSOKKmWUAO4HR7r424DgiYaUZusQ8MzvXzNLNrDfwM2AJnQ5vFIkFKnSJB9NoWyLZDIwGLnb911RikJZcRERihGboIiIxIjGoJ87JyfHhw4cH9fQiIlFp/vz55e6e29V9gRX68OHDmTdvXlBPLyISlcxs/Z7u05KLiEiMUKGLiMQIFbqISIxQoYuIxIi9FrqZPd6+c8vSPdxvZva/7bu3LDazyeGPKSIiexPKDP0J4IzPuP9M2s6+Gw1cTdsuLSIi0sP2Wuju/g+g4jOGTAOe8jYfANlmNjhcAUVEJDThOA49jw47s9B2idA82i4Z+h/M7GraZvEUFBSE4alFRCKDu9PQ3EpVfRM19c3UNDTv/lzb2ExtQwt1jc3UNbYwZVhfjh/d5blBByQchd7VZgFdXiDG3R8BHgEoLCzURWREJCK1tjo76hopr2lke00D22sb2VHXSEVtIzvrmthR1/a5clfbR3V9E1W7mmlsCW3b2P868aCILfQSOmy1Rdt2X5vD8LgiImFX39TC5p272LRzF1sq69mys56tVfWUVtWzrbqe0qq2Am9p7XrO2Sc1kez0ZPqmJ9EnLYn8vmlkpbV9nZmaSGZqEpkpiWSkJJKR2vY5PTmh7XNKImlJCST02q9Ns/YqHIU+C7jOzGYCRwKV7v6p5RYRkZ5SWdfEmvIa1pbXsq68lg0Vde0fuyiv+fRmVf17JzOwTyoD+6QwfnAfcjNTyM1IISczhX69k+nfu+1z3/QkEhMi92jvvRa6mT0LnAjkmFkJcAeQBODuM4DXgbOAYqAOmN5dYUVEOqqqb6JoazUrt1RRtK2a4tIaiktrKK9p3D2ml8HgrDQK+qVz8tgB5PdNI69vGkOy08jLTmNAnxRSEhMCfBXhs9dCd/dL9nK/07Z3oohIt6nc1cSijTtZsqmSpZsqWbq5ko0Vu3bfn5mayOgBGZw8diAHDejNiJwMRuT0Zmi/tJgp7L0J7GqLIiJ74u6s217H3HUVzF1bwYINO1hdVrv7/mH905mYn83FRxQwfnAfxgzKZHBWKmbdszYdLVToIhIRNu/cxT+Ly/n36u28v7qcbVVta93Z6UlMKejL+YfnMamgL4fmZ5GVlhRw2sikQheRQDS3tPLhugreXlnKO0VlfFxaA0BORjJHH5TDUSP7MXV4Pw7KzaBXNx0VEmtU6CLSY+qbWninqIw3l23lbytLqdzVRHJCL6aO6MeXjxjK8aNzOXhgRtwvnewvFbqIdKumllbe+7iMWQs389bybdQ2tpCdnsTJ4wZw2vhBHD86h94pqqJw0N+iiHSLlVureGFeCS8v3ER5TSNZaUmcM3EI5xw2mKNH9o/o47mjlQpdRMKmvqmFVxdv4Zk561mwYSdJCcbnxw7gC5PzOXHMAJITVeLdSYUuIgdsa2U9T/17Hc98uIGddU2MzOnND88ex4WT8+nXOznoeHFDhS4i+23VtmpmvLOaWYs20+rOaeMHccUxwzh6ZH+9sRkAFbqI7LMlJZU88PbHzF62jfTkBC4/ehjTjxlBQf/0oKPFNRW6iISsaGs1//NmEW8u30af1ET+78mjmX7McPpqWSUiqNBFZK827dzFz2YX8fLCTWQkJ/KdUw5m+nHD6ZOqMzYjiQpdRPaotqGZGe+u5pF/rAHg6hNGcs0JB2lGHqFU6CLyKe7Onxdv4e5Xl1Na3cC0w4fwgzPGkpedFnQ0+QwqdBH5D2vLa7nt5aX8s7icQ/OyeOgrU5gyrG/QsSQEKnQRAdoulvXoe2v5xV9XkZLQizunHcJlRw7rtu3SJPxU6CLCqm3V3PD8IhaVVHLmhEH8+LxDGNAnNehYso9U6CJxrLXVefxfa/npG0VkpCby4KWTOXvi4KBjyX5SoYvEqdLqer733CLe+7icU8cP5J4LDyUnIyXoWHIAVOgicegfq8r4zh8XUtvYzE8umMClUwt0qn4MUKGLxJHWVufXfy/ml39bxcEDMpl56VGMHpgZdCwJExW6SJyorGvi+j9+xDtFZVwwKY+fXDCB9GRVQCzRv6ZIHCgureEbT82jZEcdd50/ga8cqSWWWKRCF4lx764q47pnFpCc0Itnv3EUhcP7BR1JuokKXSSG/f6D9dzxylIOHpjJY18tJL+vLm8by1ToIjHI3fnZm0U8+PZqPj92AL++ZJI2Yo4D+hcWiTFNLa3c+OJiXlqwiUumDuWuaRO0IXOcUKGLxJD6phaufXoBf1tZyndPPZhvfX6U3vyMIyp0kRhR29DMN56ax7/XbOcnF0zgsiOHBR1JepgKXSQGVO5qYvrvPmRRSSU//9JhXDApP+hIEgAVukiUq9zVxBW/ncPyLVU8eOkkzpigi2vFq5DeKTGzM8ysyMyKzeymLu7PMrM/m9kiM1tmZtPDH1VEOquub+Krj3/I8i1VPHTZFJV5nNtroZtZAvAgcCYwHrjEzMZ3GnYtsNzdDwNOBP7HzLTpoEg3+qTMl26q5MFLJ3PK+IFBR5KAhTJDnwoUu/sad28EZgLTOo1xINPa3k7PACqA5rAmFZHd6ptauOrJeSwqqeSBSydx2iGDgo4kESCUQs8DNna4XdL+vY4eAMYBm4ElwPXu3tr5gczsajObZ2bzysrK9jOySHxramnl2qcXMHddBT//0mFaZpHdQin0rg5i9U63TwcWAkOAw4EHzKzPp/6Q+yPuXujuhbm5ufsYVURaW50fvLCYv60s5c5pE5h2eOe5lcSzUAq9BBja4XY+bTPxjqYDL3mbYmAtMDY8EUXkE3e/toI/fbSJG04fw+VH6Thz+U+hFPpcYLSZjWh/o/NiYFanMRuAkwHMbCAwBlgTzqAi8e63/1zL4/9ay/Rjh/N/Tjwo6DgSgfZ6HLq7N5vZdcBsIAF43N2Xmdk17ffPAO4CnjCzJbQt0dzo7uXdmFskrvxlyRbufm05Z04YxG1nj9fp/NKlkE4scvfXgdc7fW9Gh683A6eFN5qIAMxfX8H1f1zI5IK+/OLLh9Orl8pcuqZLsIlEsI0VdXzjqfkMyUrl0SsKSU1KCDqSRDAVukiEqmlo5utPzqO5pZXffu0I+vXWuXry2XQtF5EI1NLqfHvmRxSX1fDE9CM4KDcj6EgSBTRDF4lA988u4q8rSrn9nPEcP1rnbEhoVOgiEea1xVuY8e5qLplawBVH61hzCZ0KXSSCrNpWzQ0vLGJSQTY/Ok+HJ8q+UaGLRIiq+ia++fv5pCcn8tBlU0hJ1BEtsm9U6CIRwN353nOL2FhRx28um8ygrNSgI0kUUqGLRIDf/nMtby3fxs1njWPqiH5Bx5EopUIXCdj89Tu49y8rOf2QgVx57PCg40gUU6GLBGhHbSPfemYBg7NT+elFh+lNUDkgOrFIJCDuzvefX0R5TSMv/tcxZKUlBR1Jopxm6CIBeeL9dfxtZSm3nDWWQ/Ozgo4jMUCFLhKAZZsruef1lZwybgBfPWZ40HEkRqjQRXpYXWMz33r2I7LTk7RuLmGlNXSRHnbnn5eztryWp686UldQlLDSDF2kB81etpWZczfyzRMO4phROUHHkRijQhfpIWXVDdz80hLGD+7Dd089OOg4EoNU6CI9wN258cXF1DQ088uLDyc5Ub96En76qRLpAc9+uJG/ryzlpjPGcvDAzKDjSIxSoYt0sw3b67j7teUcO6o/X9MhitKNVOgi3ai11bnhhUUkmHH/RYfRq5cOUZTuo0IX6UZP/nsdc9ZWcNs54xmSnRZ0HIlxKnSRbrKmrIb73ljJSWNy+WJhftBxJA6o0EW6QUurc8MLi0lO6MW9X5ios0GlR6jQRbrBk++vY/76Hdxx7iEM7KPdh6RnqNBFwmzD9jrun13EiWNyuXByXtBxJI6o0EXC6JMTiBJ6Gf99waFaapEepUIXCaNnP9zIv9ds55azxumoFulxKnSRMNlaWc89r6/g6JH9uWTq0KDjSBxSoYuEgbtz2ytLaWxp5d4vaKlFghFSoZvZGWZWZGbFZnbTHsacaGYLzWyZmb0b3pgike2NpVt5a/k2vnPqwQzr3zvoOBKn9rrBhZklAA8CpwIlwFwzm+XuyzuMyQZ+A5zh7hvMbEA35RWJOJV1Tdw+axmHDOnD148bEXQciWOhzNCnAsXuvsbdG4GZwLROYy4FXnL3DQDuXhremCKR6943VlBR28h9X5hIYoJWMSU4ofz05QEbO9wuaf9eRwcDfc3sHTObb2ZXdPVAZna1mc0zs3llZWX7l1gkgsxZs51nP9zIVceNYEJeVtBxJM6FUuhdvbvjnW4nAlOAs4HTgdvM7FNbsrj7I+5e6O6Fubm5+xxWJJI0NLdwy5+WkN83jW+fMjroOCIhbRJdAnQ8Bisf2NzFmHJ3rwVqzewfwGHAqrCkFIlAD7+7htVltfxu+hGkJ2u/dQleKDP0ucBoMxthZsnAxcCsTmNeAY43s0QzSweOBFaEN6pI5FhTVsMDbxdz9sTBnDRGxwBIZNjrtMLdm83sOmA2kAA87u7LzOya9vtnuPsKM3sDWAy0Ao+5+9LuDC4SFHfnhy8vJSWxF3ecMz7oOCK7hfT/RHd/HXi90/dmdLp9P3B/+KKJRKaXF27i/dXbufv8CQzQlRQlgugYK5F9UFnXxN2vrmBSQTaXTi0IOo7If9A7OSL74L7ZK9lR18hTV03V/qAScTRDFwnR/PU7eGbOBqYfO4JDhuiYc4k8KnSREDS3tHLrn5YwqE8q3zn1U6dYiEQEFbpICJ54fx0rt1Zzx7njyUjRSqVEJhW6yF5sqdzFL95axUljcjljwqCg44jskQpdZC/ufnUFza3Oj8+boOucS0RToYt8hndXlfHaki1cd9IoCvqnBx1H5DOp0EX2oL6phdtfWcrInN5c/bmRQccR2Su9uyOyBzPeXc367XX84aojSUlMCDqOyF5phi7ShfXba/nNO6s5Z+JgjhudE3QckZCo0EU6cXfumLWM5IRe3KaLb0kUUaGLdDJ72TbeKSrjO6cezEBdfEuiiApdpIO6xmbu/PMyxg7K5KtHDws6jsg+UaGLdPCrv33M5sp67j5/gjZ8lqijn1iRdh9vq+a3763lS4X5FA7vF3QckX2mQhfh/+9ClJGayE1njgs6jsh+UaGL0LYL0Zy1Fdx4xlj69U4OOo7IflGhS9yr3NXET15bweFDs/ly4dCg44jsN50pKnHvf94soqK2kSemaxciiW6aoUtcW1yyk99/sJ4rjh7OhDztQiTRTYUucaulte2N0JyMFL57mnYhkuinQpe49cyHG1hcUskPzx5Hn9SkoOOIHDAVusSlsuoGfvrGSo4d1Z/zDhsSdByRsFChS1z6yWvLqW9q4c5p2oVIYocKXeLOv4rLeXnhZv7rcwdxUG5G0HFEwkaFLnGlvqmFH768lGH90/k/J40KOo5IWOk4dIkrD7+7hrXltTx15VRSk7QLkcQWzdAlbqwtr+XBd4o597AhnHBwbtBxRMJOhS5xoe3iW0tISejFbWfr4lsSm1ToEhdeXriJfxVv5wdnjmWAdiGSGBVSoZvZGWZWZGbFZnbTZ4w7wsxazOyi8EUUOTA7ahu569UVTCrI5rKpBUHHEek2ey10M0sAHgTOBMYDl5jZp3bObR93HzA73CFFDsQ9f1lB1a4m7rnwUF18S2JaKDP0qUCxu69x90ZgJjCti3HfAl4ESsOYT+SAfLBmO8/NK+Hrx49k7KA+QccR6VahFHoesLHD7ZL27+1mZnnABcCMz3ogM7vazOaZ2byysrJ9zSqyT+qbWrj5pSUU9Evn+pNHBx1HpNuFUuhd/R/VO93+JXCju7d81gO5+yPuXujuhbm5OmxMutev//4xa8tr+e8LDiUtWcecS+wL5cSiEqDjNi75wOZOYwqBme3XxMgBzjKzZnd/ORwhRfbVii1VPPzuGi6aks9xo3OCjiPSI0Ip9LnAaDMbAWwCLgYu7TjA3Ud88rWZPQG8qjKXoLS0Oje9uJistCRuPUvHnEv82Guhu3uzmV1H29ErCcDj7r7MzK5pv/8z181Fetrv/rWWRSWV/O8lk+irDZ8ljoR0LRd3fx14vdP3uixyd//agccS2T/rt9fyszeLOHnsAM6dODjoOCI9SmeKSsxobXVufHExSb168ZMLDtV1ziXuqNAlZjzz4QY+WFPBD88Zx6Asnd4v8UeFLjFh085d3PuXlRw3KocvFQ7d+x8QiUEqdIl67m1HtbS6c8+FWmqR+KVCl6j3zIcbeO/jcm45axxD+6UHHUckMCp0iWobK+r4yWsrOG5UDpcdqSspSnxToUvUam11vv/8InqZcd9FE7XUInFPhS5R64n31zFnbQW3nTOOvOy0oOOIBE6FLlHp423V3PfGSk4ak6ujWkTaqdAl6jQ2t/LtPy6kd0qillpEOgjp1H+RSPKrv61i2eYqHr58CgMydQKRyCc0Q5eoMm9dBQ+9s5ovFeZz+iGDgo4jElFU6BI1Knc1cf3MheT1TeP2cw8JOo5IxNGSi0QFd+eWl5awraqe5685mowU/eiKdKYZukSF5+Zt5LUlW/juaQczqaBv0HFEIpIKXSLe6rIafjRrOceO6s81JxwUdByRiKVCl4hW39TCtU8vIC05gZ9/6XB69dIhiiJ7ooVIiWh3vLKMlVureWL6EQzso0MURT6LZugSsV6cX8If523kupNGceKYAUHHEYl4KnSJSB9vq+aHLy/lyBH9+PYpo4OOIxIVVOgScarrm/jmH+bTOyWBX18yicQE/ZiKhEJr6BJRWlud7z23iPXb63j660cyQOvmIiHT1EciykPvrubN5du45axxHDWyf9BxRKKKCl0ixjtFpfzszSKmHT6EK48dHnQckaijQpeIUFxaw7ee/Yixg/pw74W6JK7I/lChS+B21jXy9SfnkpLYi0evmEJackLQkUSikt4UlUA1tbRy7TML2LyznmevPpL8vulBRxKJWip0CYy786NZy/hX8XZ+9sXDmDKsX9CRRKKallwkMA+9u5qn52zgms8dxEVT8oOOIxL1VOgSiFcWbuKnbxRx3mFD+MHpY4KOIxITVOjS495fXc73n1/EkSP6cf8XJ+oKiiJhElKhm9kZZlZkZsVmdlMX919mZovbP943s8PCH1ViwdJNlVz91HyG9e/NI5cXkpKoI1pEwmWvhW5mCcCDwJnAeOASMxvfadha4HPuPhG4C3gk3EEl+q0uq+Grj39IVloSv79qKlnpSUFHEokpoczQpwLF7r7G3RuBmcC0jgPc/X1339F+8wNA73DJf9i8cxeXPzYHgN9fNZXBWWkBJxKJPaEUeh6wscPtkvbv7clVwF+6usPMrjazeWY2r6ysLPSUEtVKq+r5ymNzqK5v5skrpzIyNyPoSCIxKZRC7+odK+9yoNlJtBX6jV3d7+6PuHuhuxfm5uaGnlKiVml1PZc8+gFbq+r53fQjmJCXFXQkkZgVyolFJcDQDrfzgc2dB5nZROAx4Ex33x6eeBLNymsauOzROWyprOeJ6VMpHK4Th0S6Uygz9LnAaDMbYWbJwMXArI4DzKwAeAm43N1XhT+mRJvSqnoueeQDNu6o4/GvHcHUESpzke621xm6uzeb2XXAbCABeNzdl5nZNe33zwBuB/oDv2m/Sl6zuxd2X2yJZCU76rjssTmUVzfwu69N1XXNRXqIuXe5HN7tCgsLfd68eYE8t3SfNWU1XPbYHGob2t4AnVTQN+hIIjHFzObvacKsi3NJ2Cwu2cmVT8zFHWZefTTjh/QJOpJIXNGp/xIWbxeVcvEjH5CalMBz16jMRYKgGbocsOfmbuTmPy1h7KBMfjf9CAZkamNnkSCo0GW/tbQ6P31jJQ//Yw3Hj87hoa9MISNFP1IiQdFvn+yX6vomrp+5kL+vLOXyo4Zx+7njSUrQCp5IkFToss9Wl9Vwze/ns6a8lrumHcLlRw8POpKIoEKXffT6ki3c8PwiUpISeOrKqRw7KifoSCLSToUuIWlsbuW+N1by23+uZVJBNg9eOpkh2bpiokgkUaHLXq0uq+H6mR+xdFMVXztmOLecNY7kRK2Xi0QaFbrskbvzx7kb+fGfl5Oa1ItHryjk1PEDg44lInugQpcubancxU0vLuHdVWUcO6o/P//S4Qzso+PLRSKZCl3+g7vz3LyN3P3qCppbnR+dO54rjh6ujZxFooAKXXb7eFs1t768lA/XVjB1RD/uv2giw/r3DjqWiIRIhS7UNjTzwNvFPPqPNfROSeSeCw/ly4VDNSsXiTIq9DjW2uq8sKCE+2cXUVbdwBcm53PLWWPpn5ESdDQR2Q8q9Djk7rz3cTk/nb2SpZuqOHxoNg9fPoXJuna5SFRToceZeesquH92EXPWVpCXncavLj6c8w4bQvtOUyISxVToccDd+fea7Tzw92LeX72dnIwU7px2CF8+YigpiQlBxxORMFGhx7CWVuet5dt49L01zF+/g9zMFG49axyXHVVAerL+6UVijX6rY1BVfRMvzCvhiffXsaGijvy+adx1/gS+OCWf1CTNyEVilQo9Rrg7SzZV8vQHG5i1aDO7mlooHNaXm88cy2mHDCJBhyCKxDwVepQrra7nlY828+KCElZurSYtKYHzJw3h0qnDODQ/K+h4ItKDVOhRaGddI7OXbeXVxVt4f/V2Wlqdw4Zmc9e0Q5g2KY8+qUlBRxSRAKjQo8TWynreWrGNN5dt5YM122lqcQr6pfPNE0Zy4eR8Rg3ICDqiiARMhR6hmlta+WjjTt4pKuWdojKWba4CYEROb648dgRnTxzMoXlZOn5cRHZToUeI5pZWVm6t5oM123l/9XY+XFtBTUMzCb2MKQV9ueH0MZx+yEAOys1QiYtIl1ToAdlR28jCkp0s3LCTBRt2sGD9DmobWwAYmdOb8ycN4ZiDcjh2VA5ZaVoTF5G9U6F3M3entLqBlVurWb65iqWbKlm6uZL12+sAMIMxAzO5cHI+hcP7MnVEPwZnaa9OEdl3KvQwaW11tlTVs7asltVlNXxcWs3H22pYta2aHXVNu8cN7ZfGoXlZfPmIoRw+NJuJ+dlkpOifQUQOnJokRO5OVX0zm3bsYtPOXWzaUceGil1sqKhlQ0Ud67fX0dDcunt8ZmoiowdkcNr4QYwbnMnYwX0YN6gPWelaPhGR7hH3hd7S6uysa6SitpHymkbKahoor26gtLqB0qp6tlXXs7Wyni2V9dS1r3F/Ii0pgYJ+6Qzr35sTRucyMjeDETm9GZnbmwGZKXrzUkR6VEiFbmZnAL8CEoDH3P3eTvdb+/1nAXXA19x9QZizdsndaWhupbahmdqGFqobmqipb6a6vpnqhiaqdjVTtauJyl1N7Gz/vKO2kR11jeysa2JHXSOt/unHTUowBmSmMqBPCmMGZfK5gwcwOCuVIdlp5PdNI69vGv17J6u0RSRi7LXQzSwBeBA4FSgB5prZLHdf3mHYmcDo9o8jgYfaP4fd20Wl3P3qcuoaW6htaKausYXmrhq5k/TkBLLSkshKS6JvejJjBmWSnZ5M/97J9Gv/yM1IITczhZyMFLLTk1TWIhJVQpmhTwWK3X0NgJnNBKYBHQt9GvCUuzvwgZllm9lgd98S7sBZaUmMHdyH9KQEeqckkpacQEZKIr2T225npiaRmZpIZmoifXZ/nURyYq9wRxERiSihFHoesLHD7RI+Pfvuakwe8B+FbmZXA1cDFBQU7GtWACYX9GXypdoqTUSks1CmrV2tO3Re4whlDO7+iLsXunthbm5uKPlERCREoRR6CTC0w+18YPN+jBERkW4USqHPBUab2QgzSwYuBmZ1GjMLuMLaHAVUdsf6uYiI7Nle19DdvdnMrgNm03bY4uPuvszMrmm/fwbwOm2HLBbTdtji9O6LLCIiXQnpOHR3f5220u74vRkdvnbg2vBGExGRfaFj+UREYoQKXUQkRqjQRURihLUtfwfwxGZlwPpAnvzA5ADlQYfoYXrNsS/eXi9E72se5u5dnsgTWKFHKzOb5+6FQefoSXrNsS/eXi/E5mvWkouISIxQoYuIxAgV+r57JOgAAdBrjn3x9nohBl+z1tBFRGKEZugiIjFChS4iEiNU6AfAzL5vZm5mOUFn6U5mdr+ZrTSzxWb2JzPLDjpTdzGzM8ysyMyKzeymoPN0NzMbamZvm9kKM1tmZtcHnamnmFmCmX1kZq8GnSVcVOj7ycyG0rbP6oags/SAt4AJ7j4RWAXcHHCebtFh/9wzgfHAJWY2PthU3a4Z+J67jwOOAq6Ng9f8ieuBFUGHCCcV+v77BfADutiZKda4+5vu3tx+8wPaNjCJRbv3z3X3RuCT/XNjlrtvcfcF7V9X01ZwecGm6n5mlg+cDTwWdJZwUqHvBzM7D9jk7ouCzhKAK4G/BB2im+xpb9y4YGbDgUnAnICj9IRf0jYhaw04R1iFdD30eGRmfwUGdXHXrcAtwGk9m6h7fdbrdfdX2sfcStt/0Z/uyWw9KKS9cWORmWUALwLfdveqoPN0JzM7Byh19/lmdmLAccJKhb4H7n5KV983s0OBEcAiM4O25YcFZjbV3bf2YMSw2tPr/YSZfRU4BzjZY/fkhbjcG9fMkmgr86fd/aWg8/SAY4HzzOwsIBXoY2Z/cPevBJzrgOnEogNkZuuAQnePxqu2hcTMzgB+DnzO3cuCztNdzCyRtjd9TwY20baf7qXuvizQYN3I2mYlTwIV7v7tgOP0uPYZ+vfd/ZyAo4SF1tAlFA8AmcBbZrbQzGbs7Q9Eo/Y3fj/ZP3cF8Fwsl3m7Y4HLgc+3/9subJ+5ShTSDF1EJEZohi4iEiNU6CIiMUKFLiISI1ToIiIxQoUuIhIjVOgiIjFChS4iEiP+HxVk9BLS3GPrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "jump = .1\n",
    "x = np.arange(-5., 5 + jump, jump) #Generate x = -5, -5 + 0.1, -5 + 2 * 0.1, ..., 5 (jump = 0.1 gives 0.1 jumps!)\n",
    "\n",
    "plot_function(sigmoid, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea7550a",
   "metadata": {},
   "source": [
    "In addition to the S-shape, we always obtain values that are within $[0,1]$. This is because the logistic function always takes values between $0$ and $1$. To see this, observe that as $z \\rightarrow \\infty$ we have $e^{-z}= 0$ hence $s(z) = 1$ and as $z \\rightarrow 0$ we have $e^{-z} = \\infty$ hence $s(z) = 0$. \n",
    "\n",
    "Thanks to this property, we typically use the sigmoid function to come up with \"probabilities\" for an instance to belong to either of two classes in a standard classification setting, though there are many extensions possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c15060a",
   "metadata": {},
   "source": [
    "Neural networks use activation functions. We will soon see how to use many of them in an integrated manner to make sophisticated decisions. However, to illustrate the simplest case, we now present a neural network for two-dimensional predictors. \n",
    "\n",
    "Assume for simplicity that in a classification problem every instance has $x_1,\\ x_2$ values, and our goal is to find the target $y$. We use logistic regression, which returns the probability of an instance having a target, say $+1$ as:\n",
    "$$ \\mathbb{P}[y = 1 | x_1, x_2] = \\dfrac{1}{ 1 + \\exp( - w_0 - w_1 x_1 -  w_2 x_2)} = s(w_0 + w_1x_2 + w_2x_2).$$\n",
    "\n",
    "In logistic regression we optimize the parameters $w_0, w_1, w_2$ to make the most meaningful classifications.\n",
    "\n",
    "This procedure can be summarized by a very simple neural network:\n",
    "<img src=\"logistic.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "We interpret this network as the following: The input of the network is an instance with variables $x_1$ and $x_2$. There is also an input which is always $+1$ (called the *bias*). The weight of the input $x_1$ is $w_1$, the weight of the input $x_2$ is $w_2$, and the weight of the input $+1$ is $w_0$. The input gets transformed by $w_0 + w_1 x_1 + w_2 x_2$ and enters the activation node. The activation node applies the function $s$ and returns the answer of $s(w_0 + w_1 x_1 + w_2 x_2)$. Our goal is to optimize the weights ($w_0,\\ w_1,\\ w_2$) of this system so that the final decision is the most meaningful. Note that, the \"most meaningul\" phrase is vague right now, and soon we will formalize this (the weigths are chosen to minimize a loss over a training set)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62975fa2",
   "metadata": {},
   "source": [
    "We can shift and scale the sigmoid function as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707b5fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def modified_sigmoid(z):\n",
    "    \"\"\"The modified sigmoid function.\"\"\"\n",
    "    z = 10*z + 10\n",
    "    return sigmoid(z)\n",
    "plot_function(modified_sigmoid, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4820e6ba",
   "metadata": {},
   "source": [
    "However, in neural networks we will not need to worry about which scaling or shifting to take, as the weights will be optimized in a way that the corresponding 'shape' of the sigmoid function will make the best predictions. In general, for any $w_1, w_2, w_0$ in the above example, if we, for example, take new weights as $2w_1, 2w_2, 2w_0$, then we scaled the input of sigmoid function by $2$. Similarly, if we update $w_0$ as $w_0 + 2$, we shift the input of sigmoid by $2$. Hence, we keep sigmoid function's description as simple as possible, whose input is a scalar $z$. However, in a neural network, the definition of $z$ depends on the weights coming in this activation node and the output of the previous 'layer'. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24415cee",
   "metadata": {},
   "source": [
    "#### ReLU (Rectified Linear Unit)\n",
    "The ReLU function simply keeps the positive part of its argument:\n",
    "$$r(x) = \\max \\{0, x\\}. $$\n",
    "Sometimes this function is referred as $\\mathrm{ReLU(x)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb0b4132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def relu(z):\n",
    "    \"\"\"The relu function.\"\"\"\n",
    "    return np.maximum(0,z)\n",
    "plot_function(relu, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb66379",
   "metadata": {},
   "source": [
    "#### Leaky ReLU\n",
    "The Leaky ReLU function is simply changing the definition of ReLU slightly for negative inputs:\n",
    "\n",
    "$$ rl(x) = \\begin{cases}\n",
    "x & \\text{ if } x> 0 \\\\\n",
    "0.01x & \\text{ otherwise.}\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a3a4376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def leaky_relu(z): #using 0.1 instead of 0.01 just to make the plot easier to read\n",
    "    \"\"\"The leaky relu function.\"\"\"\n",
    "    return 0.1*z + 0.9*np.maximum(0,z)\n",
    "plot_function(leaky_relu, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bdc6ac",
   "metadata": {},
   "source": [
    "#### Softplus\n",
    "Smooth approximation of the ReLU function:\n",
    "$$ sp(x) =  \\log(1 + e^{x})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dee19ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def sofplus(z):\n",
    "    \"\"\"The sofplus function.\"\"\"\n",
    "    return np.log(1 + np.exp(z))\n",
    "plot_function(sofplus, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13b2654",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "The Exponential linear unit (ELU) activation, for some $\\alpha > 0$ is:\n",
    "$$el(X) = \\begin{cases} \\alpha \\cdot( e^x - 1) & \\text{ if } x \\leq 0 \\\\  x  & \\text{ if } x > 0 \\end{cases}.$$\n",
    "Visualize this activation function for $\\alpha = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5c3248",
   "metadata": {},
   "source": [
    "There are many more activation functions. However, for now, we move on to how to design a simple neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1617ccc",
   "metadata": {},
   "source": [
    "### 2. Building simple neural networks\n",
    "Let us use the ReLU function above to make some simple predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e5f0fa",
   "metadata": {},
   "source": [
    "Assume that a training point consists of $p$ predictors $\\{x_i\\}_{i = 1,\\ldots, p}$ and a target $y$. Our goal is to 'learn' a function that maps the predictors to the target as accurately as possible **with a fixed network architecture** (as otherwise we can design an arbitrarily deep neural network which can learn everything but it will overfit the training set). Assume this is a regression problem.\n",
    "\n",
    "For simplicity of notation, let us denote the ReLU activation function as $[y]_+ = \\max\\{0, y\\}$. If $y$ is a vector, then our understanding for $[y]_+$ is that the ReLU function will be applied to each component of $y$.\n",
    "\n",
    "Now, for a matrix $W \\in \\mathbb{R}^{q \\times p}$, a vector $b \\in \\mathbb{R}^q$, and a matrix with a single row $H \\in \\mathbb{R}^{1 \\times q}$, let our estimation for $y$ be:\n",
    "$$\\hat{y} = H [W x + b]_+.$$\n",
    "Here, the rule can be verbally explain as the following: Take the input $x$ and (pre-) multiply it with a matrix $W$ and add a vector $b$ (so we applied an affine transformation on $x$). Take the positive part of the resulting vector. Then, (pre-) multiply this result by $H$ to obtain the final answer. Although this rule might initially look vague, it is shown to be a very strong rule in most settings. See [this SIAM news article](https://sinews.siam.org/Details-Page/the-functions-of-deep-learning) for more details.\n",
    "\n",
    "In neural networks, our goal is to optimize the 'weights' (or parameters) $W, b, H$ to come up with the best estimation $\\hat{y}$ of $y$. The visual description of the above architecture can be summarized as:\n",
    "<img src=\"simple_nn.png\" alt=\"Drawing\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df55ba",
   "metadata": {},
   "source": [
    "In this network, we see that there are $p$ inputs (which are corresponding to the elements of some $x \\in \\mathbb{R}^p$). Moreover, there is an additional input of a fixed constant, $+1$, which is the *bias* term (to see why bias term is useful, see [this discussion](https://stats.stackexchange.com/a/153945/206540])). There is a single hidden layer with $q$ neurons, each denotes as $r_j$ for $j = 1,\\ldots,q$. The input of the $j$-th neuron in the hidden layer is: $z_j := w_{j1}x_1 + w_{j2}x_2 + \\ldots, w_{jp}x_p + b_j$. Moreover, the output of this neuron is the ReLU activation of its input $r_j = [z_j]_{+}$. Finally, the output layer uses the weights $H = [h_1 \\ \\cdots \\ h_q]$ to come up with the estimation $\\hat{y} = h_1 r_1 + \\ldots + h_q r_q$.\n",
    "\n",
    "Finally, note that:\n",
    "- The fact that there are $q$ neurons in the hidden layer is a modeling decision. This is the fixed architecture. In neural networks, we optimize the weights after fixing an architecture. So, in our optimization problem, we will not consider what value of $q$ to take. Same applies to the selection of the activation function as well as the fact that there is only one hidden layer.\n",
    "- We discussed that the above network is a visual representation of the estimation $H [W x + b]_+$. This compact representation is obtained by matrix multiplications. To use this representation, we must note that $H$ is a matrix whose $(1,j)$-th value is $h_j$, $W$ is a matrix whose $(j,i)$-th value is $w_{ji}$, and $b$ is a vector whose $j$-th element is $b_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe2a746",
   "metadata": {},
   "source": [
    "Above, we saw a very simple neural network. We have not discussed how to optimize its weights, neither did we explore options to generalize this network. We will be able to add as many hidden layers as possible to the network, with different activation functions and neuron numbers (depths). Similarly, we will be able to add the bias term to each layer. Moroever, we will also be able to have multi-class classification/regression by having multiple neurons in the output layer rather than just one.\n",
    "\n",
    "To this end, we now discuss some of the useful properties that we will use in the following. We will see shortly that deep neural networks ('deep' corresponds to increasing the number of layers) can be used to approximate any function, and that it generalizes some of our old friends, including the linear and logistic regressions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa913d0",
   "metadata": {},
   "source": [
    "There are 5 important steps in creating a function $F(x, w)$ that corresponds to the decision of a neural network, where $w$ are weights and $x$ the data:\n",
    "1. Key operation: **Composition** $F = F_3(F_2(F_1(x, w))))$ (*e.g.*, recall how we multiplied $x$ with a matrix, added a vector, multiplied with another, etc., we composed many functions!).\n",
    "2. Key algorithm: **Stochastic Gradient Descent** to find the best weights $w$.\n",
    "3. Key rule: **Chain rule** to compute derivatives that are used in stochastic gradient descent (the 'chain' comes from the composition).\n",
    "4. Key subroutine: **Backpropagation** to execute the chain rule efficiently.\n",
    "5. Key nonlinearity: **Rectifier** $\\text{ReLU}(y) = r(y) = [y]_+$ ramp function, that we introduced before (will be simply referred as rectifier).\n",
    "\n",
    "Above, the first element (composition) will be used to add more complexity to the network. In the above example we used a single hidden layer and the composition we took was a linear (multiplying with $H$) - sigmoid (applying $[\\cdot]_+$) - affine (applying $Wx + b$ to the input). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe29db9",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "**Exercise:**\n",
    "Write the explicit functional expression describing the following network architecture displayed in the diagram below (from [1]). You can assume that the activation function from layer 2 to layer 3 is of ReLU type. Moreover, assume that there is a bias term connecting to each layer. Count the number of weights in this architecture. \n",
    "\n",
    "<img src=\"demond_fig3.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "\n",
    "\n",
    "*** \n",
    "\n",
    "#### Reading: \n",
    "1. Deep Learning: An Introduction for Applied Mathematicians, Desmond Higham, Arxiv:1801.05894 \n",
    "2. Approximation by superpositions of a sigmoidal function, Mathematics of Control, Signals, and Systems 7 (1989) 303-314"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62148d4",
   "metadata": {},
   "source": [
    "### 3. Using PyTorch for Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7308e7a",
   "metadata": {},
   "source": [
    "To compute with Neural Networks, we will be using Python library `torch`: \n",
    "```python\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3) #example usage\n",
    "```\n",
    "In the course of this section and the next two sections we will explain the library's API in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0926508b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c92f3ea41741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f03ba0",
   "metadata": {},
   "source": [
    "Using `PyTorch` we're going to rewrite the example above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b046ca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a429e7210c0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# in PyTorch we have to start defining the linear functions of each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mF_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#bias = True adds the bias term for input - layer 1 weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as func \n",
    "\n",
    "# in PyTorch we have to start defining the linear functions of each layer\n",
    "F_1 = nn.Linear(in_features=2, out_features=2, bias=True) #bias = True adds the bias term for input - layer 1 weights\n",
    "print('A_2:', F_1.weight, '\\n', 'b_2:', F_1.bias) #weights are assigned randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b729fcd",
   "metadata": {},
   "source": [
    "From `F_2` above we can define a function in Python using either the `lambda` or the `def` keywords: \n",
    "\n",
    "```python \n",
    "def F_2(x):\n",
    "    return F_2.forward(x) # or just F_2(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "becf51d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.1859, 0.0000], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(np.array([1., 2.], dtype=np.float64)).float() #use numpy commands -- example input to Layer 2\n",
    "L_2 = nn.Linear(in_features=2, out_features=3, bias=True) #define the second step -> 2 - to 3 + the bias term \n",
    "F_2 = lambda x: func.relu(L_2.forward(x)) # F_2 applies the ReLU activation on the L_2 evaluation.\n",
    "F_2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526e081",
   "metadata": {},
   "source": [
    "We can apply the above steps by simple algebra, so what `torch` applies is not a mystery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cc6db8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.       ],\n",
       "       [1.1858686],\n",
       "       [0.       ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = L_2.weight.detach().numpy() #the weights L2 uses are taken\n",
    "x_vect = x.detach().numpy().reshape(2,1) #we take the input as a numpy array\n",
    "input_of_L_2 = weights.dot(x_vect) + L_2.bias.detach().numpy().reshape(3,1) #now apply the affine transformation\n",
    "output_of_L2 = relu(input_of_L_2) #composition with the relu function (activate the input)\n",
    "output_of_L2 #this is what F_2 returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb408fb",
   "metadata": {},
   "source": [
    "Finally we apply the last layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "159ef22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_3 = nn.Linear(in_features=3, out_features=2, bias=True)\n",
    "F_3 = lambda x: L_3.forward(x) #this is just evaluation, here we do not apply ReLU (or this is \"identity activation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f6e83",
   "metadata": {},
   "source": [
    "We defined all layers. Now, to make prediction, we can simply compose the layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb7fa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = lambda x: F_3(F_2(F_1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f585573b",
   "metadata": {},
   "source": [
    "And finally giving an input to `F` will return an output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eaf6afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0856, -0.4549], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(np.array([1., 2.], dtype=np.float64)).float()\n",
    "y = F(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9092de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0856, -0.4549], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.from_numpy(np.array([-2, 5], dtype=np.float64)).float()\n",
    "y = F(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986d423",
   "metadata": {},
   "source": [
    "Note that `F` is just a function with fixed weights. The reason is since `torch` automatically assigns initial weights. In the next notebook we will see how to optimize the weigths for a purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add16242",
   "metadata": {},
   "source": [
    "#### 4. Visualizing a Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e6c10a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.47.3 (20210619.1520)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"460pt\" height=\"479pt\"\n",
       " viewBox=\"0.00 0.00 460.00 479.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 475)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-475 456,-475 456,4 -4,4\"/>\n",
       "<!-- 140460623002896 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140460623002896</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"278,-31 219,-31 219,0 278,0 278,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (1, 2)</text>\n",
       "</g>\n",
       "<!-- 140460623050064 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140460623050064</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"299,-86 198,-86 198,-67 299,-67 299,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 140460623050064&#45;&gt;140460623002896 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>140460623050064&#45;&gt;140460623002896</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.5,-66.79C248.5,-60.07 248.5,-50.4 248.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252,-41.19 248.5,-31.19 245,-41.19 252,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140460623051792 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140460623051792</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"183,-141 82,-141 82,-122 183,-122 183,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"132.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140460623051792&#45;&gt;140460623050064 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140460623051792&#45;&gt;140460623050064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M151.14,-121.98C169.8,-113.46 198.75,-100.23 220.24,-90.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"221.88,-93.51 229.52,-86.17 218.97,-87.14 221.88,-93.51\"/>\n",
       "</g>\n",
       "<!-- 140460622999696 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140460622999696</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"162,-207 103,-207 103,-177 162,-177 162,-207\"/>\n",
       "<text text-anchor=\"middle\" x=\"132.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">W3.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"132.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n",
       "</g>\n",
       "<!-- 140460622999696&#45;&gt;140460623051792 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140460622999696&#45;&gt;140460623051792</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M132.5,-176.84C132.5,-169.21 132.5,-159.7 132.5,-151.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"136,-151.27 132.5,-141.27 129,-151.27 136,-151.27\"/>\n",
       "</g>\n",
       "<!-- 140460623049776 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140460623049776</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"296,-141 201,-141 201,-122 296,-122 296,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"248.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140460623049776&#45;&gt;140460623050064 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140460623049776&#45;&gt;140460623050064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.5,-121.75C248.5,-114.8 248.5,-104.85 248.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252,-96.09 248.5,-86.09 245,-96.09 252,-96.09\"/>\n",
       "</g>\n",
       "<!-- 140460623049920 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140460623049920</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"282,-201.5 181,-201.5 181,-182.5 282,-182.5 282,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"231.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 140460623049920&#45;&gt;140460623049776 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140460623049920&#45;&gt;140460623049776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.01,-182.37C236.39,-174.16 240.06,-161.54 243.11,-151.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.55,-151.75 245.98,-141.17 239.83,-149.79 246.55,-151.75\"/>\n",
       "</g>\n",
       "<!-- 140460623051648 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140460623051648</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-267.5 0,-267.5 0,-248.5 101,-248.5 101,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140460623051648&#45;&gt;140460623049920 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140460623051648&#45;&gt;140460623049920</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M74.91,-248.37C106.58,-237.17 161.97,-217.58 197.68,-204.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"198.93,-208.23 207.19,-201.6 196.59,-201.63 198.93,-208.23\"/>\n",
       "</g>\n",
       "<!-- 140460623002976 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140460623002976</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"59,-339 0,-339 0,-309 59,-309 59,-339\"/>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-327\" font-family=\"monospace\" font-size=\"10.00\">W2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-316\" font-family=\"monospace\" font-size=\"10.00\"> (3)</text>\n",
       "</g>\n",
       "<!-- 140460623002976&#45;&gt;140460623051648 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140460623002976&#45;&gt;140460623051648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.16,-308.8C37.18,-299.6 41.14,-287.53 44.4,-277.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.81,-278.44 47.6,-267.84 41.15,-276.25 47.81,-278.44\"/>\n",
       "</g>\n",
       "<!-- 140460623052272 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140460623052272</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"263,-267.5 162,-267.5 162,-248.5 263,-248.5 263,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"212.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 140460623052272&#45;&gt;140460623049920 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140460623052272&#45;&gt;140460623049920</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M215.06,-248.37C217.85,-238.97 222.39,-223.67 226,-211.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"229.37,-212.49 228.86,-201.91 222.65,-210.5 229.37,-212.49\"/>\n",
       "</g>\n",
       "<!-- 140460623049536 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140460623049536</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"178,-333.5 77,-333.5 77,-314.5 178,-314.5 178,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140460623049536&#45;&gt;140460623052272 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140460623049536&#45;&gt;140460623052272</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.96,-314.37C152.78,-303.97 176.21,-286.32 192.91,-273.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"195.06,-276.51 200.95,-267.7 190.85,-270.92 195.06,-276.51\"/>\n",
       "</g>\n",
       "<!-- 140460065957104 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140460065957104</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"157,-405 98,-405 98,-375 157,-375 157,-405\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-393\" font-family=\"monospace\" font-size=\"10.00\">W1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"127.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n",
       "</g>\n",
       "<!-- 140460065957104&#45;&gt;140460623049536 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140460065957104&#45;&gt;140460623049536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.5,-374.8C127.5,-365.7 127.5,-353.79 127.5,-343.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"131,-343.84 127.5,-333.84 124,-343.84 131,-343.84\"/>\n",
       "</g>\n",
       "<!-- 140460623049872 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140460623049872</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"273,-333.5 196,-333.5 196,-314.5 273,-314.5 273,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 140460623049872&#45;&gt;140460623052272 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140460623049872&#45;&gt;140460623052272</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M231.53,-314.37C228.3,-304.97 223.04,-289.67 218.87,-277.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"222.12,-276.22 215.56,-267.91 215.5,-278.5 222.12,-276.22\"/>\n",
       "</g>\n",
       "<!-- 140460623048912 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140460623048912</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"285,-399.5 184,-399.5 184,-380.5 285,-380.5 285,-399.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5\" y=\"-387.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140460623048912&#45;&gt;140460623049872 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140460623048912&#45;&gt;140460623049872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.5,-380.37C234.5,-371.16 234.5,-356.29 234.5,-344.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"238,-343.91 234.5,-333.91 231,-343.91 238,-343.91\"/>\n",
       "</g>\n",
       "<!-- 140460476975840 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140460476975840</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"270,-471 199,-471 199,-441 270,-441 270,-471\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5\" y=\"-459\" font-family=\"monospace\" font-size=\"10.00\">W1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"234.5\" y=\"-448\" font-family=\"monospace\" font-size=\"10.00\"> (2, 2)</text>\n",
       "</g>\n",
       "<!-- 140460476975840&#45;&gt;140460623048912 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140460476975840&#45;&gt;140460623048912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.5,-440.8C234.5,-431.7 234.5,-419.79 234.5,-409.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"238,-409.84 234.5,-399.84 231,-409.84 238,-409.84\"/>\n",
       "</g>\n",
       "<!-- 140460623052320 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>140460623052320</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"358,-267.5 281,-267.5 281,-248.5 358,-248.5 358,-267.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.5\" y=\"-255.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 140460623052320&#45;&gt;140460623049920 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140460623052320&#45;&gt;140460623049920</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M307.63,-248.37C293.33,-237.97 269.07,-220.32 251.78,-207.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"253.61,-204.75 243.46,-201.7 249.49,-210.41 253.61,-204.75\"/>\n",
       "</g>\n",
       "<!-- 140460623049248 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>140460623049248</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"392,-333.5 291,-333.5 291,-314.5 392,-314.5 392,-333.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"341.5\" y=\"-321.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140460623049248&#45;&gt;140460623052320 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>140460623049248&#45;&gt;140460623052320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M338.53,-314.37C335.3,-304.97 330.04,-289.67 325.87,-277.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"329.12,-276.22 322.56,-267.91 322.5,-278.5 329.12,-276.22\"/>\n",
       "</g>\n",
       "<!-- 140460623002576 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>140460623002576</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"377,-405 306,-405 306,-375 377,-375 377,-405\"/>\n",
       "<text text-anchor=\"middle\" x=\"341.5\" y=\"-393\" font-family=\"monospace\" font-size=\"10.00\">W2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"341.5\" y=\"-382\" font-family=\"monospace\" font-size=\"10.00\"> (3, 2)</text>\n",
       "</g>\n",
       "<!-- 140460623002576&#45;&gt;140460623049248 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>140460623002576&#45;&gt;140460623049248</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M341.5,-374.8C341.5,-365.7 341.5,-353.79 341.5,-343.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"345,-343.84 341.5,-333.84 338,-343.84 345,-343.84\"/>\n",
       "</g>\n",
       "<!-- 140460623051552 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>140460623051552</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"430,-141 353,-141 353,-122 430,-122 430,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"391.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 140460623051552&#45;&gt;140460623050064 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>140460623051552&#45;&gt;140460623050064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M368.52,-121.98C345,-113.27 308.21,-99.63 281.56,-89.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"282.49,-86.36 271.89,-86.17 280.05,-92.93 282.49,-86.36\"/>\n",
       "</g>\n",
       "<!-- 140460623052560 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>140460623052560</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"452,-201.5 351,-201.5 351,-182.5 452,-182.5 452,-201.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"401.5\" y=\"-189.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140460623052560&#45;&gt;140460623051552 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>140460623052560&#45;&gt;140460623051552</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M400.02,-182.37C398.62,-174.16 396.46,-161.54 394.67,-151.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"398.12,-150.43 392.98,-141.17 391.22,-151.61 398.12,-150.43\"/>\n",
       "</g>\n",
       "<!-- 140460066425648 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>140460066425648</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"447,-273 376,-273 376,-243 447,-243 447,-273\"/>\n",
       "<text text-anchor=\"middle\" x=\"411.5\" y=\"-261\" font-family=\"monospace\" font-size=\"10.00\">W3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"411.5\" y=\"-250\" font-family=\"monospace\" font-size=\"10.00\"> (2, 3)</text>\n",
       "</g>\n",
       "<!-- 140460066425648&#45;&gt;140460623052560 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>140460066425648&#45;&gt;140460623052560</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M409.28,-242.8C407.86,-233.7 406,-221.79 404.45,-211.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"407.88,-211.18 402.88,-201.84 400.97,-212.26 407.88,-211.18\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fbf898abdc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here's another way of constructing your computational graph by using the library torchviz\n",
    "# we will discuss computational models again later in this module\n",
    "from torch.autograd import Variable\n",
    "from torchviz import make_dot \n",
    "model = nn.Sequential()\n",
    "model.add_module('W1', nn.Linear(2,2)) #add a layer with linear transformation as before\n",
    "model.add_module('W2', nn.Linear(2,3)) #add another layer similarly\n",
    "model.add_module('relu', nn.ReLU()) #add a ReLU activation\n",
    "model.add_module('W3', nn.Linear(3, 2)) #add a final linear layer\n",
    "x = Variable(torch.randn(1, 2)) #input variable\n",
    "y = model(x)\n",
    "make_dot(y, params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bede946b",
   "metadata": {},
   "source": [
    "We can change the activation functions and number of layers for different purposes. For example, we can represent logistic regression with the architecture shown in the beginning of this notebook. We can visualise the architecture by using `torchviz`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf94afff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.47.3 (20210619.1520)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"216pt\" height=\"391pt\"\n",
       " viewBox=\"0.00 0.00 216.00 391.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 387)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-387 212,-387 212,4 -4,4\"/>\n",
       "<!-- 140460065957664 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140460065957664</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"130.5,-31 76.5,-31 76.5,0 130.5,0 130.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140459796560432 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140459796560432</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"148,-86 59,-86 59,-67 148,-67 148,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MaxBackward1</text>\n",
       "</g>\n",
       "<!-- 140459796560432&#45;&gt;140460065957664 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140459796560432&#45;&gt;140460065957664</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-66.79C103.5,-60.07 103.5,-50.4 103.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-41.19 103.5,-31.19 100,-41.19 107,-41.19\"/>\n",
       "</g>\n",
       "<!-- 140459796558560 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140459796558560</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-141 47,-141 47,-122 160,-122 160,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">SigmoidBackward0</text>\n",
       "</g>\n",
       "<!-- 140459796558560&#45;&gt;140459796560432 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140459796558560&#45;&gt;140459796560432</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-121.75C103.5,-114.8 103.5,-104.85 103.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-96.09 103.5,-86.09 100,-96.09 107,-96.09\"/>\n",
       "</g>\n",
       "<!-- 140459796561872 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140459796561872</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-196 53,-196 53,-177 154,-177 154,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 140459796561872&#45;&gt;140459796558560 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140459796561872&#45;&gt;140459796558560</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.5,-176.75C103.5,-169.8 103.5,-159.85 103.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107,-151.09 103.5,-141.09 100,-151.09 107,-151.09\"/>\n",
       "</g>\n",
       "<!-- 140459796558080 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140459796558080</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140459796558080&#45;&gt;140459796561872 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140459796558080&#45;&gt;140459796561872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M59.25,-231.75C66.97,-224.03 78.4,-212.6 87.72,-203.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.31,-205.64 94.91,-196.09 85.36,-200.69 90.31,-205.64\"/>\n",
       "</g>\n",
       "<!-- 140460066425968 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140460066425968</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"80,-317 21,-317 21,-287 80,-287 80,-317\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\">W0.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (2)</text>\n",
       "</g>\n",
       "<!-- 140460066425968&#45;&gt;140459796558080 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140460066425968&#45;&gt;140459796558080</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-286.84C50.5,-279.21 50.5,-269.7 50.5,-261.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-261.27 50.5,-251.27 47,-261.27 54,-261.27\"/>\n",
       "</g>\n",
       "<!-- 140459796558608 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140459796558608</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"196,-251 119,-251 119,-232 196,-232 196,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 140459796558608&#45;&gt;140459796561872 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140459796558608&#45;&gt;140459796561872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M148.58,-231.75C140.72,-224.03 129.07,-212.6 119.58,-203.28\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"121.84,-200.6 112.25,-196.09 116.94,-205.59 121.84,-200.6\"/>\n",
       "</g>\n",
       "<!-- 140459796559040 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140459796559040</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-311.5 107,-311.5 107,-292.5 208,-292.5 208,-311.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-299.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140459796559040&#45;&gt;140459796558608 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140459796559040&#45;&gt;140459796558608</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.5,-292.37C157.5,-284.25 157.5,-271.81 157.5,-261.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"161,-261.17 157.5,-251.17 154,-261.17 161,-261.17\"/>\n",
       "</g>\n",
       "<!-- 140460604904928 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140460604904928</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"193,-383 122,-383 122,-353 193,-353 193,-383\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\">W0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"157.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\"> (2, 2)</text>\n",
       "</g>\n",
       "<!-- 140460604904928&#45;&gt;140459796559040 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140460604904928&#45;&gt;140459796559040</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.5,-352.8C157.5,-343.7 157.5,-331.79 157.5,-321.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"161,-321.84 157.5,-311.84 154,-321.84 161,-321.84\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fbf58477880>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is how a simple logistic regression would look like\n",
    "model = nn.Sequential()\n",
    "model.add_module('W0', nn.Linear(2, 2))\n",
    "model.add_module('logit', nn.Sigmoid()) #sigmoid activation\n",
    "x = Variable(torch.randn(1, 2))\n",
    "y = model(x)\n",
    "make_dot(y.max(), params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43002fd8",
   "metadata": {},
   "source": [
    "The strange name of the operations and variables in the PyTorch computational graph may not make much sense right now, but as we progress in this class we'll be piecing the different parts of the puzzle together. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c786ac",
   "metadata": {},
   "source": [
    "#### 5. Demonstration of the Logistic Regression via a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3353c66",
   "metadata": {},
   "source": [
    "In the beginning of this notebook, we discussed that in the two-dimensional feature setting, the probability of an instance to belong the target +1 (assuming there are two targets) is\n",
    "$$ \\mathbb{P}[y = 1 | x_1, x_2] = \\dfrac{1}{ 1 + \\exp( - w_0 - w_1 x_1 -  w_2 x_2)} = s(w_0 + w_1x_2 + w_2x_2).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf215b84",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "Find the probability $\\mathbb{P}[y = 1 | x_1, x_2]$ where $w_0 = 1, w_1 = 0.3, w_2 = -0.1$ for the input $x = (x_1 = 1, x_2 = -2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b97881",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "Model the same with a simple neural network. Report the probability of the same input belonging class +1 when the weights are fixed accordingly.\n",
    "*(Hint: the weights within two layers are automatically being initialized via `torch`, however, you may change it by ```L_1.weight.data = ...``` and ```L_1.bias.data = ...```)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
